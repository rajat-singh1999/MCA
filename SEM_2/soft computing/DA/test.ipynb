{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the path to the dataset folder\n",
    "dataset_path = 'archive\\Rice_Image_Dataset'  # Update with your dataset path\n",
    "\n",
    "# Get the list of rice types (subfolders)\n",
    "rice_types = os.listdir(dataset_path)\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each rice type\n",
    "for rice_type in rice_types:\n",
    "    rice_type_path = os.path.join(dataset_path, rice_type)\n",
    "    # Iterate through each image in the rice type folder\n",
    "    for image_file in os.listdir(rice_type_path):\n",
    "        image_path = os.path.join(rice_type_path, image_file)\n",
    "        # Load the image and add it to the images list\n",
    "        images.append(image_path)\n",
    "        # Add the label (rice type) to the labels list\n",
    "        labels.append(rice_type)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print('Training samples:', len(train_images))\n",
    "print('Test samples:', len(test_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rice_type_path, image_file)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Load the image and add it to the images list\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m image \u001b[38;5;241m=\u001b[39m img_to_array(image)\n\u001b[0;32m     29\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the path to the dataset folder\n",
    "dataset_path = 'archive\\Rice_Image_Dataset'  # Update with your dataset path\n",
    "\n",
    "# Get the list of rice types (subfolders)\n",
    "rice_types = os.listdir(dataset_path)\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each rice type\n",
    "for rice_type in rice_types:\n",
    "    rice_type_path = os.path.join(dataset_path, rice_type)\n",
    "    # Iterate through each image in the rice type folder\n",
    "    for image_file in os.listdir(rice_type_path):\n",
    "        image_path = os.path.join(rice_type_path, image_file)\n",
    "        # Load the image and add it to the images list\n",
    "        image = load_img(image_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        images.append(image)\n",
    "        # Add the label (rice type) to the labels list\n",
    "        labels.append(rice_type)\n",
    "\n",
    "# Convert the images and labels to numpy arrays\n",
    "images = np.array(images, dtype='float32')\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform one-hot encoding on the labels\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, onehot_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Training samples:', len(train_images))\n",
    "print('Test samples:', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the dataset folder\n",
    "dataset_path = 'archive\\Rice_Image_Dataset'  # Update with your dataset path\n",
    "\n",
    "# Get the list of rice types (subfolders)\n",
    "rice_types = os.listdir(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each rice type\n",
    "for rice_type in rice_types:\n",
    "    rice_type_path = os.path.join(dataset_path, rice_type)\n",
    "    # Iterate through each image in the rice type folder\n",
    "    xyz = os.listdir(rice_type_path)[0:1000]\n",
    "    for image_file in xyz:\n",
    "        image_path = os.path.join(rice_type_path, image_file)\n",
    "        # Load the image and add it to the images list\n",
    "        image = load_img(image_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        images.append(image)\n",
    "        # Add the label (rice type) to the labels list\n",
    "        labels.append(rice_type)\n",
    "\n",
    "# Convert the images and labels to numpy arrays\n",
    "images = np.array(images, dtype='float32')\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the labels\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, onehot_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4000\n",
      "Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "print('Training samples:', len(train_images))\n",
    "print('Test samples:', len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;28mlen\u001b[39m(rice_types), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m sgd \u001b[38;5;241m=\u001b[39m \u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39msgd, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\sgd.py:111\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[1;34m(self, learning_rate, momentum, nesterov, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     97\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    110\u001b[0m ):\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    112\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    113\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    114\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[0;32m    115\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[0;32m    116\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[0;32m    117\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[0;32m    118\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[0;32m    119\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[0;32m    120\u001b[0m         jit_compile\u001b[38;5;241m=\u001b[39mjit_compile,\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    122\u001b[0m     )\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m momentum\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer.py:1087\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1074\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1084\u001b[0m ):\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;124;03m\"\"\"Create a new Optimizer.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1087\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1088\u001b[0m         name,\n\u001b[0;32m   1089\u001b[0m         weight_decay,\n\u001b[0;32m   1090\u001b[0m         clipnorm,\n\u001b[0;32m   1091\u001b[0m         clipvalue,\n\u001b[0;32m   1092\u001b[0m         global_clipnorm,\n\u001b[0;32m   1093\u001b[0m         use_ema,\n\u001b[0;32m   1094\u001b[0m         ema_momentum,\n\u001b[0;32m   1095\u001b[0m         ema_overwrite_frequency,\n\u001b[0;32m   1096\u001b[0m         jit_compile,\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1098\u001b[0m     )\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer.py:105\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iteration_variable()\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer.py:134\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m legacy_kwargs:\n\u001b[1;32m--> 134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    135\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated in the new Keras optimizer, please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy optimizer, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         )\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.SGD."
     ]
    }
   ],
   "source": [
    "# Define the AlexNet model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(256, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(384, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(rice_types), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Convert ground truth labels to class labels\n",
    "true_labels = label_encoder.inverse_transform(np.argmax(test_labels, axis=1))\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
