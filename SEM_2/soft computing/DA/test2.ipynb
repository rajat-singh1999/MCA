{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f8b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import ResNet50, VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f38a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52500 images belonging to 5 classes.\n",
      "Found 22500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'archive\\Rice_Image_Dataset'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4ace4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1641/1641 [==============================] - 1564s 952ms/step - loss: 0.2343 - accuracy: 0.9093 - val_loss: 0.1763 - val_accuracy: 0.9412\n",
      "Epoch 2/10\n",
      "1641/1641 [==============================] - 1501s 915ms/step - loss: 0.1223 - accuracy: 0.9627 - val_loss: 0.1478 - val_accuracy: 0.9505\n",
      "Epoch 3/10\n",
      "1641/1641 [==============================] - 1293s 788ms/step - loss: 0.1069 - accuracy: 0.9666 - val_loss: 0.1345 - val_accuracy: 0.9512\n",
      "Epoch 4/10\n",
      "1641/1641 [==============================] - 1277s 778ms/step - loss: 0.0971 - accuracy: 0.9709 - val_loss: 0.1548 - val_accuracy: 0.9576\n",
      "Epoch 5/10\n",
      "1641/1641 [==============================] - 1279s 780ms/step - loss: 0.0918 - accuracy: 0.9730 - val_loss: 0.1367 - val_accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "1641/1641 [==============================] - 1284s 783ms/step - loss: 0.0894 - accuracy: 0.9743 - val_loss: 0.1553 - val_accuracy: 0.9562\n",
      "Epoch 7/10\n",
      "1641/1641 [==============================] - 1279s 779ms/step - loss: 0.0791 - accuracy: 0.9766 - val_loss: 0.1653 - val_accuracy: 0.9476\n",
      "Epoch 8/10\n",
      "1641/1641 [==============================] - 1614s 983ms/step - loss: 0.0806 - accuracy: 0.9756 - val_loss: 0.1234 - val_accuracy: 0.9600\n",
      "Epoch 9/10\n",
      "1641/1641 [==============================] - 1397s 852ms/step - loss: 0.0733 - accuracy: 0.9781 - val_loss: 0.1081 - val_accuracy: 0.9666\n",
      "Epoch 10/10\n",
      "1641/1641 [==============================] - 1418s 864ms/step - loss: 0.0771 - accuracy: 0.9775 - val_loss: 0.1482 - val_accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Sequential()\n",
    "alexnet_model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "alexnet_model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "alexnet_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(Flatten())\n",
    "alexnet_model.add(Dense(4096, activation='relu'))\n",
    "alexnet_model.add(Dropout(0.5))\n",
    "alexnet_model.add(Dense(4096, activation='relu'))\n",
    "alexnet_model.add(Dropout(0.5))\n",
    "alexnet_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "alexnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "alexnet_history = alexnet_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0c1a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_directory = \\'/path/to/test_dataset\\'\\n\\ntest_datagen = ImageDataGenerator(rescale=1./255)\\n\\ntest_generator = test_datagen.flow_from_directory(\\n    test_directory,\\n    target_size=(224, 224),\\n    batch_size=32,\\n    class_mode=\\'categorical\\',\\n    shuffle=False\\n)\\n\\n# Evaluate AlexNet model\\nalexnet_scores = alexnet_model.evaluate(test_generator)\\nprint(\"AlexNet Test Loss:\", alexnet_scores[0])\\nprint(\"AlexNet Test Accuracy:\", alexnet_scores[1])\\n\\n# Evaluate ResNet model\\nresnet_scores = resnet_model.evaluate(test_generator)\\nprint(\"ResNet Test Loss:\", resnet_scores[0])\\nprint(\"ResNet Test Accuracy:\", resnet_scores[1])\\n\\n# Evaluate VGGNet model\\nvgg_scores = vgg_model.evaluate(test_generator)\\nprint(\"VGGNet Test Loss:\", vgg_scores[0])\\nprint(\"VGGNet Test Accuracy:\", vgg_scores[1])\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "resnet_model = Sequential()\n",
    "resnet_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "resnet_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "resnet_model.layers[0].trainable = False\n",
    "\n",
    "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "resnet_history = resnet_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG16(include_top=False, pooling='avg', weights='imagenet'))\n",
    "vgg_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "vgg_history = vgg_model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "test_directory = '/path/to/test_dataset'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate AlexNet model\n",
    "alexnet_scores = alexnet_model.evaluate(test_generator)\n",
    "print(\"AlexNet Test Loss:\", alexnet_scores[0])\n",
    "print(\"AlexNet Test Accuracy:\", alexnet_scores[1])\n",
    "\n",
    "# Evaluate ResNet model\n",
    "resnet_scores = resnet_model.evaluate(test_generator)\n",
    "print(\"ResNet Test Loss:\", resnet_scores[0])\n",
    "print(\"ResNet Test Accuracy:\", resnet_scores[1])\n",
    "\n",
    "# Evaluate VGGNet model\n",
    "vgg_scores = vgg_model.evaluate(test_generator)\n",
    "print(\"VGGNet Test Loss:\", vgg_scores[0])\n",
    "print(\"VGGNet Test Accuracy:\", vgg_scores[1])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0a5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_directory = 'archive\\Rice_Image_Dataset'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b29cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2344/2344 [==============================] - 308s 131ms/step - loss: 0.0839 - accuracy: 0.9738\n",
      "AlexNet Test Loss: 0.08389470726251602\n",
      "AlexNet Test Accuracy: 0.9738266468048096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate AlexNet model\n",
    "alexnet_scores = alexnet_model.evaluate(test_generator)\n",
    "print(\"AlexNet Test Loss:\", alexnet_scores[0])\n",
    "print(\"AlexNet Test Accuracy:\", alexnet_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b67670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
